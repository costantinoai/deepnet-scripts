{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd844304",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from kornia import rgb_to_grayscale\n",
    "import torch.nn as nn\n",
    "import warnings\n",
    "import random, textwrap\n",
    "import os, glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.util import random_noise\n",
    "from skimage import util\n",
    "from skimage import exposure\n",
    "from scipy import ndimage\n",
    "from datetime import datetime\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "log = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9604830",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_filters_multi_channel(t, path=''):\n",
    "\n",
    "    #get the number of kernels\n",
    "    num_kernels = t.shape[0]\n",
    "\n",
    "    #define number of columns for subplots\n",
    "    num_cols = 12\n",
    "    #rows = num of kernels\n",
    "    num_rows = num_kernels\n",
    "\n",
    "    #set the figure size\n",
    "    fig = plt.figure(figsize=(num_cols,num_rows))\n",
    "\n",
    "    #looping through all the kernels\n",
    "    for i in range(t.shape[0]):\n",
    "        ax1 = fig.add_subplot(num_rows,num_cols,i+1)\n",
    "\n",
    "        #for each kernel, we convert the tensor to numpy\n",
    "        npimg = np.array(t[i].numpy(), np.float32)\n",
    "        #standardize the numpy image\n",
    "        npimg = (npimg - np.mean(npimg)) / np.std(npimg)\n",
    "        npimg = np.minimum(1, np.maximum(0, (npimg + 0.5)))\n",
    "        npimg = npimg.transpose((1, 2, 0))\n",
    "        ax1.imshow(npimg)\n",
    "        ax1.axis('off')\n",
    "        ax1.set_title(str(i))\n",
    "        ax1.set_xticklabels([])\n",
    "        ax1.set_yticklabels([])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if path != '':\n",
    "        plt.savefig(path)\n",
    "    plt.show()\n",
    "\n",
    "## TRANSFORMATIONS\n",
    "def no_trans(base):\n",
    "    return base\n",
    "\n",
    "# random noise\n",
    "def rnd_noise(base):\n",
    "    original_image = np.array(base).astype('uint8')\n",
    "    base_noise = random_noise(original_image)\n",
    "    return Image.fromarray(np.uint8(base_noise*255))\n",
    "\n",
    "# color inversion\n",
    "def col_inv(base):\n",
    "    original_image = np.array(base).astype('uint8')\n",
    "    base_inv = np.invert(original_image)\n",
    "    return Image.fromarray(np.uint8(base_inv))\n",
    "\n",
    "# contrast correction\n",
    "def cont_corr(base):\n",
    "    original_image = np.array(base).astype('uint8')\n",
    "    v_min, v_max = np.percentile(original_image, (15, 85))\n",
    "    base_contr = exposure.rescale_intensity(original_image, in_range=(v_min, v_max))\n",
    "    return Image.fromarray(np.uint8(base_contr))\n",
    "\n",
    "# gamma correction\n",
    "def gamma_corr(base):\n",
    "    original_image = np.array(base).astype('uint8')\n",
    "    base_gamma = exposure.adjust_gamma(original_image, gamma=0.4, gain=0.9)\n",
    "    return Image.fromarray(np.uint8(base_gamma))\n",
    "\n",
    "# log correction\n",
    "def log_corr(base):\n",
    "    original_image = np.array(base).astype('uint8')\n",
    "    base_log = exposure.adjust_log(original_image)\n",
    "    return Image.fromarray(np.uint8(base_log))\n",
    "\n",
    "# horizontal flip\n",
    "def hflip(base):\n",
    "    original_image = np.array(base).astype('uint8')\n",
    "    base_hflip = original_image[:, ::-1]\n",
    "    return Image.fromarray(np.uint8(base_hflip))\n",
    "\n",
    "# blur\n",
    "def blur(base):\n",
    "    original_image = np.array(base).astype('uint8')\n",
    "    base_blur = ndimage.uniform_filter(original_image, size=(10, 10, 1))\n",
    "    return Image.fromarray(np.uint8(base_blur))\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        # V1 layers\n",
    "        self.V1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=7 // 2),  # + self.vfb,\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "        )\n",
    "\n",
    "        # V2 layers\n",
    "        self.V2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=3 // 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "        )\n",
    "\n",
    "        # V4 layers\n",
    "        self.V4 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=3 // 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "        )\n",
    "\n",
    "        # IT layers\n",
    "        self.IT = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=3 // 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "        )\n",
    "\n",
    "        # decoding layer\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1), nn.Flatten(), nn.Linear(512, 2),\n",
    "        )\n",
    "\n",
    "    def forward(self, inp):\n",
    "\n",
    "        # v4 = torch.zeros(512, 256, 3, 3).to(\"cuda\")\n",
    "        # vIT = torch.zeros(256, 128, 3, 3).to(\"cuda\")\n",
    "        # v2 = torch.zeros(256, 128, 3, 3).to(\"cuda\")\n",
    "        # v1 = torch.zeros(128, 64, 3, 3).to(\"cuda\")\n",
    "        x = inp.to(\"cuda\")\n",
    "\n",
    "        v1 = self.V1(x).to(\"cuda\")\n",
    "        v2 = self.V2(v1).to(\"cuda\")\n",
    "        v4 = self.V4(v2).to(\"cuda\")\n",
    "        vIT = self.IT(v4).to(\"cuda\")\n",
    "        out = self.decoder(vIT).to(\"cuda\")\n",
    "\n",
    "        return out\n",
    "\n",
    "def show_images(before, after):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2)\n",
    "    ax = axes.ravel()\n",
    "    ax[0].imshow(before, cmap='gray')\n",
    "    ax[0].set_title(\"Original image\")\n",
    "\n",
    "    ax[1].imshow(after, cmap='gray')\n",
    "    ax[0].axis('off')\n",
    "    ax[1].axis('off')\n",
    "    plt.tight_layout()\n",
    "\n",
    "def label_from_path(path):\n",
    "    split_name = path.stem.split(\"_\")\n",
    "    return \"same\" if (split_name[-1] == split_name[-2]) else \"different\"\n",
    "\n",
    "def display_images(\n",
    "    images: [Image.Image],\n",
    "    columns=5, width=20, height=8, max_images=15,\n",
    "    label_wrap_length=50, label_font_size=8):\n",
    "\n",
    "    if not images:\n",
    "        print(\"No images to display.\")\n",
    "        return\n",
    "\n",
    "    if len(images) > max_images:\n",
    "        print(f\"Showing {max_images} images of {len(images)}:\")\n",
    "        images=images[0:max_images]\n",
    "\n",
    "    height = max(height, int(len(images)/columns) * height)\n",
    "    plt.figure(figsize=(width, height))\n",
    "    for i, image in enumerate(images):\n",
    "\n",
    "        plt.subplot(int(len(images) / columns + 1), columns, i + 1)\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "\n",
    "        plt.imshow(image)\n",
    "\n",
    "        if hasattr(image, 'filename'):\n",
    "            title=image.filename\n",
    "            if title.endswith(\"/\"): title = title[0:-1]\n",
    "            title=os.path.basename(title)\n",
    "            title=textwrap.wrap(title, label_wrap_length)\n",
    "            title=\"\\n\".join(title)\n",
    "            plt.title(title, fontsize=label_font_size);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f90ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_path = r\"\\stimuli\\samediff_no-trans\"\n",
    "\n",
    "## THIS WAS USED TO PAIR THE STIMULI\n",
    "# os.makedirs(stim_path, exist_ok=True)\n",
    "# stim_paths = glob.glob(os.path.join(root, '*.png'))\n",
    "\n",
    "# stims_dict = {path: {'category': os.path.basename(path)[0], 'id':os.path.basename(path).split('.')[0][1:]} for path in stim_paths}\n",
    "\n",
    "# cat_index = [\"m\",\"f\",\"c\",\"b\"]\n",
    "# orientations = ['normal','inverted']\n",
    "\n",
    "# stim_order = np.zeros((len(cat_index), len(np.unique([int(stims_dict[item]['id']) for item in stims_dict])) * 2, 2))\n",
    "# stim_ids = np.sort(np.unique([int(stims_dict[item]['id']) for item in stims_dict]))\n",
    "\n",
    "# for stim_row in range(len(stim_ids)):\n",
    "#     for cat_id in range(len(cat_index)):\n",
    "#         # same\n",
    "#         stim_order[cat_id, stim_row, 0] = stim_ids[stim_row]\n",
    "#         stim_order[cat_id, stim_row, 1] = stim_ids[stim_row]\n",
    "\n",
    "#         # diff\n",
    "#         stim_order[cat_id, stim_row + len(stim_ids), 0] = stim_ids[stim_row]\n",
    "#         stim_order[cat_id, stim_row + len(stim_ids), 1] = np.flip(stim_ids)[stim_row]\n",
    "\n",
    "# ordered_stim_dict = {orientation : {\n",
    "#                         cat_index[category_id]: {\n",
    "#                             stim_pair_id: {\n",
    "#                                 'stim1':str(int(stim_order[category_id, stim_pair_id, 0])),\n",
    "#                                 'stim2':str(int(stim_order[category_id, stim_pair_id, 1])),\n",
    "#                                 'same':stim_order[category_id, stim_pair_id, 0] == stim_order[category_id, stim_pair_id, 1]\n",
    "#                             } for stim_pair_id in range(len(stim_order[category_id]))\n",
    "#                         } for category_id in range(stim_order.shape[0])\n",
    "#                     } for orientation in orientations}\n",
    "\n",
    "# trans_list = ['no_trans','rnd_noise','col_inv','cont_corr','gamma_corr','log_corr','blur']\n",
    "# hflip_bool = [True,False]\n",
    "\n",
    "# for orientation in orientations:\n",
    "#     for cat_id in ordered_stim_dict[orientation]:\n",
    "#         for pair_id in ordered_stim_dict[orientation][cat_id]:\n",
    "#             for trans in trans_list:\n",
    "#                 for hflip_bool_ in hflip_bool:\n",
    "#                     bg = (125,125,125)\n",
    "#                     base = Image.new('RGB', (224, 224), bg)\n",
    "\n",
    "#                     im1_path = os.path.join(root, cat_id + str(ordered_stim_dict[orientation][cat_id][pair_id]['stim1']) + '.png')\n",
    "#                     im2_path = os.path.join(root, cat_id + str(ordered_stim_dict[orientation][cat_id][pair_id]['stim2']) + '.png')\n",
    "\n",
    "#                     im1 = Image.open(im1_path)\n",
    "#                     im2 = Image.open(im2_path)\n",
    "\n",
    "#                     if hflip_bool_:\n",
    "#                         im1 = hflip(im1)\n",
    "#                         im2 = hflip(im2)\n",
    "\n",
    "#                     im1 = locals()[trans](im1)\n",
    "#                     im2 = locals()[trans](im2)\n",
    "\n",
    "#                     # regular images\n",
    "#                     if orientation == 'normal':\n",
    "#                         im1.thumbnail((224 // 4, 224//4))\n",
    "#                         base.paste(im1, (224 - im1.size[0],0))\n",
    "#                         im2.thumbnail((224//4, 224//4))\n",
    "#                         base.paste(im2, (0, 224 - im2.size[0]))\n",
    "#                     else:\n",
    "#                         im1.thumbnail((224 // 4, 224//4))\n",
    "#                         base.paste(im1, (0, 0))\n",
    "#                         im2.thumbnail((224//4, 224//4))\n",
    "#                         base.paste(im2, (224 - im2.size[0], 224 - im2.size[0]))\n",
    "\n",
    "#                     filename = trans + '_' + orientation + '_' + cat_id + str(ordered_stim_dict[orientation][cat_id][pair_id]['stim1']) + '_' + cat_id + str(ordered_stim_dict[orientation][cat_id][pair_id]['stim2']) + '.png'\n",
    "#                     if hflip_bool_:\n",
    "#                         filename = 'hflip_' + filename\n",
    "#                     out_dir = os.path.join(stim_path, filename)\n",
    "\n",
    "#                     print(filename)\n",
    "#                     base.save(out_dir)\n",
    "\n",
    "pairs = glob.glob(os.path.join(stim_path, '*.png'))\n",
    "display_images([Image.open(i) for i in random.sample(pairs, 10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681f74ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init dataloaders\n",
    "stim_path = Path(stim_path)\n",
    "fnames = sorted(get_image_files(stim_path))\n",
    "dls = ImageDataLoaders.from_path_func(stim_path, fnames, label_from_path, valid_pct=0.2, seed=42, shuffle=True, device='cuda:0', bs=10)\n",
    "dls.num_workers = -1\n",
    "print('\\nShowing first batch...')\n",
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610dc060",
   "metadata": {},
   "outputs": [],
   "source": [
    "## init net and pass one image\n",
    "net = Net().cuda()\n",
    "#weights_path = Path(r\"C:\\Users\\45027900\\Desktop\\project\\net.pt\")\n",
    "\n",
    "#if weights_path.is_file():\n",
    "#    ckpt_data = torch.load(weights_path)\n",
    "#    state_dict = ckpt_data\n",
    "#    state_dict.pop(\"FB.0.weight\")\n",
    "#    state_dict.pop(\"FB.0.bias\")\n",
    "#    state_dict[\"decoder.2.weight\"] = torch.rand((2, 512))\n",
    "#    state_dict[\"decoder.2.bias\"] = torch.rand((2))\n",
    "#    net.load_state_dict(state_dict)\n",
    "#    print('weights loaded!')\n",
    "\n",
    "image = dls.one_batch()[0][0].unsqueeze(0)\n",
    "net(image).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b696bd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#init learner\n",
    "def split_layers(model):\n",
    "    return [params(model.V1),params(model.V2),params(model.V4),params(model.IT), params(model.decoder)]\n",
    "\n",
    "learner = Learner(dls, net, metrics=accuracy, loss_func=CrossEntropyLossFlat(), opt_func=Adam, splitter=split_layers)\n",
    "learner.unfreeze()\n",
    "learner.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583f2a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SET LEARNING RATE PARAMS (ONE CYCLE POLICY), TRAIN AND PLOT LR AND ACC\n",
    "# this gives us the best learning rate. see https://github.com/sgugger/Deep-Learning/blob/master/Understanding%20the%20new%20fastai%20API%20for%20scheduling%20training.ipynb\n",
    "\n",
    "#with learn.no_bar(), learn.no_logging():\n",
    "timestamp = datetime.now().strftime(\"%d-%b-%Y_%H-%M-%S\")\n",
    "root = r'\\chk'\n",
    "path = os.path.join(root,timestamp)\n",
    "if log:\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "metrics_dict = {'train_loss':[],'valid_loss':[],'accuracy':[]}\n",
    "\n",
    "n_epoch = 50000\n",
    "div = 10\n",
    "moms=(0.95, 0.85, 0.95)\n",
    "\n",
    "#lr_max = 0.001\n",
    "lr_max = learner.lr_find()[0]\n",
    "plt.suptitle(f'lr_find = {lr_max}')\n",
    "if log:\n",
    "    plt.savefig(os.path.join(path,'lr_find.png'))\n",
    "plt.show()\n",
    "\n",
    "## USE THIS TO LOAD PREVIOUS CHECKPOINT\n",
    "#learner.load(os.path.join(path, '05-Oct-2021_22-34-41_EPOCH-1x3000_fastai.pth'))\n",
    "\n",
    "weights_start = learner.model.V1[0].weight.data.cpu()\n",
    "fig_path = os.path.join(path,'weights_start.png')\n",
    "if log:\n",
    "    plot_filters_multi_channel(weights_start, path = fig_path)\n",
    "else:\n",
    "    plot_filters_multi_channel(weights_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf1239f",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime(\"%d-%b-%Y_%H-%M-%S\")\n",
    "epochs = 1\n",
    "for epoch in range(epochs):\n",
    "    with learner.no_logging(), learner.no_bar():\n",
    "        # START\n",
    "        start = datetime.now()\n",
    "        print(f'EPOCH {str(epoch + 1)} - START - {timestamp}')\n",
    "\n",
    "        # FIT\n",
    "        learner.fit_one_cycle(n_epoch=n_epoch,lr_max=lr_max)#, moms=moms)#,div=div, cbs=EarlyStoppingCallback(monitor='valid_loss', min_delta=0.1, patience=10))\n",
    "\n",
    "        # PLOT LEARNING RATE\n",
    "        learner.recorder.plot_sched() # plot learning rate and mom\n",
    "        plt.suptitle(f'lr and momentum (lr_max = {lr_max})\\nepoch {epoch} x {n_epoch} cycles')\n",
    "        if log:\n",
    "            plt.savefig(os.path.join(path,f'lr_mom_{epoch}x{n_epoch}.png'))\n",
    "        plt.show()\n",
    "\n",
    "        # SAVE MODEL\n",
    "        if log:\n",
    "            file = os.path.join(path, f'{timestamp}_EPOCH-{epoch}x{n_epoch}_fastai.pth')\n",
    "            learner.save(file, with_opt=True, pickle_protocol=2)\n",
    "\n",
    "        # SAVE AND PLOT METRICS\n",
    "        i = 0\n",
    "        for metric in learner.recorder.metric_names:\n",
    "            if metric in metrics_dict.keys():\n",
    "                metrics_dict[metric].append(learner.recorder.values[0][i])\n",
    "                i =+ 1\n",
    "\n",
    "        recorder = learner.recorder\n",
    "        metrics =  np.stack(recorder.values)\n",
    "        names = recorder.metric_names[1:-1]\n",
    "        n = len(names) -1\n",
    "        fig, axs = subplots(1, 2)\n",
    "        axs = [ax if i < n else ax.set_axis_off() for i, ax in enumerate(axs.flatten())][:n]\n",
    "\n",
    "        for i, (name, ax) in enumerate(zip(names, [axs[0]] + axs)):\n",
    "                ax.plot(metrics[:, i], color='#1f77b4' if i == 0 else '#ff7f0e', label='valid' if i > 0 else 'train')\n",
    "                ax.set_title(name if i > 1 else 'losses')\n",
    "                ax.legend(loc='best')\n",
    "        if log:\n",
    "            plt.savefig(os.path.join(path,f'metrics_{epoch}x{n_epoch}.png'))\n",
    "\n",
    "        interp = ClassificationInterpretation.from_learner(learner)\n",
    "        interp.plot_top_losses(15)\n",
    "\n",
    "        # PLOT CONFUSION MATRIX\n",
    "        interp.plot_confusion_matrix()\n",
    "        plt.suptitle(f'Epoch {epoch} x {n_epoch} cycles')\n",
    "        if log:\n",
    "            plt.savefig(os.path.join(path,f'confmat_{epoch}x{n_epoch}.png'))\n",
    "\n",
    "        # PLOT WEIGHTS\n",
    "        weights_end = learner.model.V1[0].weight.data.cpu()\n",
    "        fig_path = os.path.join(path,f'weights_{epoch}x{n_epoch}.png')\n",
    "        if log:\n",
    "            plot_filters_multi_channel(weights_start, path = fig_path)\n",
    "        else:\n",
    "            plot_filters_multi_channel(weights_start)\n",
    "\n",
    "        end = datetime.now()\n",
    "        print(f'EPOCH {str(epoch + 1)} - END - {end}')\n",
    "        print(f'time: {end-start}')\n",
    "        print(f'left: {(end-start) * (epochs - 1 - epoch)}')\n",
    "\n",
    "# PLOT RECENT RESULTS TO MAKE SURE THE LABELS ARE CORRECT\n",
    "learner.show_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f950f990",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'weights updated: {weights_start == weights_end}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421b7b65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
